{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://help.sentiment140.com/for-students/\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 7)\n",
      "4    100120\n",
      "0     99880\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = {0: 'negative', 2: 'neutral', 4: 'positive'}\n",
    "\n",
    "columns = ['Label','Id','Timestamp','Query','User','Text']\n",
    "df = pd.read_csv('../data/external/traindata_processed.csv', encoding_errors='ignore', header=None)\n",
    "df = df.sample(200000)\n",
    "df = df.rename(columns=dict(zip(range(len(columns)), columns)))\n",
    "df['Sentiment'] = df['Label'].map(labels)\n",
    "\n",
    "print(df.shape)\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "## Lowercasing\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "\n",
    "## Remove Special Chars\n",
    "df['Text'] = df['Text'].str.replace(r'^rt\\s+@\\w+:', '', regex=True)   \n",
    "df['Text'] = df['Text'].str.replace(r'(http|@)\\S+', '', regex=True)   \n",
    "df['Text'] = df['Text'].str.replace(r'[^a-z\\':_]', ' ', regex=True)\n",
    "\n",
    "## Transform short negation form\n",
    "df['Text'] = df['Text'].str.replace(r\"(can't|cannot)\", \"can not\", regex=True)\n",
    "df['Text'] = df['Text'].str.replace(r\"n't\", \" not\", regex=True)\n",
    "\n",
    "## Remove Stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for word in ['not', 'nor', 'no']:\n",
    "    stopwords.remove(word)\n",
    "    \n",
    "df['Text'] = df['Text'].apply(\n",
    "  lambda x: ' '.join([word for word in x.split() if word not in stopwords])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000,) (180000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df['Text'], np.where(df['Label'] == 0, 0, 1) # negative = 0, positive = 1\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "VOCAB_SIZE = 8500\n",
    "OUTPUT_SEQUENCE_LENGTH = 40\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "EMBED_DIM = 256\n",
    "\n",
    "def get_vectorizer(text_data:pd.Series) -> keras.layers.TextVectorization:\n",
    "    vectorizer = keras.layers.TextVectorization(\n",
    "        max_tokens=VOCAB_SIZE,\n",
    "        output_sequence_length=OUTPUT_SEQUENCE_LENGTH,\n",
    "        standardize=None\n",
    "    )\n",
    "    vectorizer.adapt(text_data)\n",
    "    return vectorizer\n",
    "\n",
    "vectorizer = get_vectorizer(X)\n",
    "\n",
    "def vectorize_text(inputs) -> tf.Tensor:\n",
    "    return vectorizer(inputs)\n",
    "\n",
    "X_train = vectorize_text(list(X_train))\n",
    "X_valid = vectorize_text(list(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 256)         2176000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         123648    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,299,777\n",
      "Trainable params: 2,299,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "\n",
    "inputs = keras.Input(shape=(None, ), dtype='int64', name='input_layer')\n",
    "embedding = keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM)(inputs)\n",
    "bi_gru = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(64, return_sequences=True)\n",
    ")(embedding)\n",
    "pooling = keras.layers.GlobalMaxPooling1D()(bi_gru)\n",
    "dropout = keras.layers.Dropout(0.3)(pooling)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813/2813 [==============================] - 325s 114ms/step - loss: 0.4752 - accuracy: 0.7721 - val_loss: 0.4416 - val_accuracy: 0.7954\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97724915\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(['negative', 'positive'])\n",
    "\n",
    "import re\n",
    "def preprocess_text(sentence:str) -> str:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'^rt\\s+@\\w+:', '', sentence)\n",
    "    sentence = re.sub(r'(http|@)\\S+', '', sentence)\n",
    "    sentence = re.sub(r'[^a-z\\':_]', ' ', sentence)\n",
    "    sentence = re.sub(r\"(can't|cannot)\", \"can not\", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
    "    sentence = re.sub(\"\\s{2,}\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n",
    "# sentence = \"I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\"\n",
    "sentence = \"I'm a happy person and to celebrate that, I wrote about having an #awesome, #happy life.\"\n",
    "\n",
    "sentence = preprocess_text(sentence)\n",
    "sentence = vectorize_text([sentence])\n",
    "preds = model.predict(sentence)[0][0]\n",
    "\n",
    "print(preds)\n",
    "print(labels[np.where(preds < 0.5, 0, 1)])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "557e8017941bd19fb6ffbcb9ac4042c9ef1a05ad323f01a83b04aa091443d0a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp-emotion-recognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
